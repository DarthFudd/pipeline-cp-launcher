AWSTemplateFormatVersion: 2010-09-09
Description: >-
  Pipeline Control Plane
Mappings:
  RegionMap:
    ap-northeast-1:
      ami: ami-02c2df979feea2aea
    ap-northeast-2:
      ami: ami-0aa972d86814a8a3f
    ap-south-1:
      ami: ami-0bf3cb591417153e0
    ap-southeast-1:
      ami: ami-0d036a8c721d7576e
    ap-southeast-2:
      ami: ami-071f8ba5202010546
    ca-central-1:
      ami: ami-00b773e3269c8f032
    eu-central-1:
      ami: ami-05bfb95161aee6066
    eu-north-1:
      ami: ami-0a01456c818b3134c
    eu-west-1:
      ami: ami-02dbb9c30a1441c02
    eu-west-2:
      ami: ami-0b890d6e2fe748e66
    eu-west-3:
      ami: ami-00299f38a91848982
    sa-east-1:
      ami: ami-0968a32ad8b537088
    us-east-1:
      ami: ami-02b8db8c1fe3fc06d
    us-east-2:
      ami: ami-011101b52fb059fcc
    us-west-1:
      ami: ami-06a6b07d6e4a3c0b9
    us-west-2:
      ami: ami-0fde050429dd5076e

Parameters:
  KeyName:
    Description: Name of an existing EC2 KeyPair to enable SSH access to the instance
    Type: 'AWS::EC2::KeyPair::KeyName'
    ConstraintDescription: must be the name of an existing EC2 KeyPair.
    AllowedPattern: '.+'
  InstanceType:
    Description: Control Plane EC2 instance type
    Type: String
    Default: c4.xlarge
    AllowedValues:
    - c5.large
    - c5.xlarge
    - c5.2xlarge
    - c5.4xlarge
    - c5.9xlarge
    - c4.large
    - c4.xlarge
    - c4.2xlarge
    - c4.4xlarge
    - c4.8xlarge
    ConstraintDescription: must be a valid EC2 instance type.

  SSHLocation:
    Description: The IP address range that can be used to SSH to the EC2 instances
    Type: String
    MinLength: '9'
    MaxLength: '18'
    Default: 0.0.0.0/0
    AllowedPattern: '(\d{1,3})\.(\d{1,3})\.(\d{1,3})\.(\d{1,3})/(\d{1,2})'
    ConstraintDescription: must be a valid IP CIDR range of the form x.x.x.x/x.

  InstanceName:
    Description: ''
    Type: String
    Default: 'pipeline-control-plane'
    ConstraintDescription: Control plane EC2 instance name
  GithubClient:
    Description: Github oauth2 client id.
    Type: String
    ConstraintDescription: ''
    Default: ''
  GithubSecret:
    Description: Github oauth2 client secret.
    NoEcho: 'true'
    Type: String
    ConstraintDescription: ''
    Default: ''
  GithubToken:
    Description: Github personal token
    NoEcho: 'true'
    Type: String
    ConstraintDescription: ''
    Default: ''

  PipelineVersion:
    Description: Valid pipeline version
    Type: String
    ConstraintDescription: ''
    Default: '0.11.0-dev.2'

Resources:
  VaultS3Bucket:
    Type: AWS::S3::Bucket
    Properties:
      AccessControl: Private
      BucketName:  !Join [ "", [ !Ref "AWS::StackName", "-pipeline-cp-" , !Ref "AWS::AccountId"] ]
    DeletionPolicy: Retain

  VaultKMSKeyAlias:
    Type: AWS::KMS::Alias
    Properties:
      AliasName: !Join [ "", [ "alias/",!Ref "AWS::StackName" , "-pipeline-cp" ] ]
      TargetKeyId:
        Ref: VaultKMSKey

  VaultKMSKey:
    Type: AWS::KMS::Key
    Properties:
      KeyPolicy:
        Version: 2012-10-17
        Statement:
        - Sid: For vault
          Effect: Allow
          Principal:
            AWS: !Join
            - ''
            - - 'arn:aws:iam::'
              - !Ref 'AWS::AccountId'
              - ':root'
          Action: kms:*
          Resource: '*'

  ElasticLoadBalancer:
    Type: AWS::ElasticLoadBalancing::LoadBalancer
    Properties:
      LoadBalancerName: !Ref "AWS::StackName"
      AvailabilityZones:
        Fn::GetAZs: ""
      Listeners:
      - LoadBalancerPort: '80'
        InstancePort: '30080'
        Protocol: TCP
        InstanceProtocol: TCP
      - LoadBalancerPort: '443'
        InstancePort: '30443'
        Protocol: TCP
        InstanceProtocol: TCP
      HealthCheck:
        Target: tcp:30080
        HealthyThreshold: '3'
        UnhealthyThreshold: '5'
        Interval: '30'
        Timeout: '5'
      ConnectionDrainingPolicy:
        Enabled: 'true'
        Timeout: '60'

  ControlPlaneGroup:
    Type: AWS::AutoScaling::AutoScalingGroup
    Properties:
      AvailabilityZones:
        Fn::GetAZs: ""
      LaunchConfigurationName:
        Ref: "LaunchConfig"
      DesiredCapacity: '1'
      MinSize: "1"
      MaxSize: "1"
      LoadBalancerNames:
      - Ref: "ElasticLoadBalancer"
      Tags:
      - Key: Name
        Value: !Ref InstanceName
        PropagateAtLaunch: True
      - Key: !Join [ "", [ "kubernetes.io/cluster/", !Ref "AWS::StackName"] ]
        Value: "owned"
        PropagateAtLaunch: True

  LaunchConfig:
    Type: AWS::AutoScaling::LaunchConfiguration
    Properties:
      InstanceType: !Ref InstanceType
      ImageId: !FindInMap [RegionMap, !Ref "AWS::Region", ami]
      IamInstanceProfile: !Ref InstanceProfile

      UserData:
        Fn::Base64:
          Fn::Sub:
          - |
            #!/usr/bin/env bash
            set -e

            export PUBLICIP=$(curl -s http://169.254.169.254/latest/meta-data/public-ipv4)
            export PRIVATEIP=$(curl -s http://169.254.169.254/latest/meta-data/local-ipv4)
            export FQDN=$(hostname -f)
            export K8S_VERSION=v1.12.4
            export HELM_HOME=/root/.helm/

            export SIGNAL_URL="${SignalUrl}"
            export PIPELINE_VERSION=${PipelineVersion}
            export ELB=${ELB}

            export GITHUB_CLIENT=${GithubClient}
            export GITHUB_SECRET=${GithubSecret}
            export GITHUB_TOKEN=${GithubToken}

            export MYSQL_USERNAME="pipeline-rw"
            export MYSQL_PASSWORD=$(openssl rand -base64 8)

            export PGSQL_USERNAME="anchore-rw"
            export PGSQL_PASSWORD=$(openssl rand -base64 8)

            export AWS_REGION=${AwsRegion}

            export VAULT_KMS_KEY_ID=${VaultKMSKeyID}
            export VAULT_S3_BUCKET=${VaultS3Bucket}

            cat > /tmp/init.conf.tpl <<EOF
            ---
            apiVersion: kubeadm.k8s.io/v1alpha3
            kind: InitConfiguration
            apiEndpoint:
              advertiseAddress: "{{ .PRIVATEIP }}"
              bindPort: 6443
            nodeRegistration:
              name: "{{ .FQDN }}"
              kubeletExtraArgs:
                cloud-provider: aws
                hostname-override: ""
              taints: []

            ---
            apiVersion: kubeadm.k8s.io/v1alpha3
            clusterName: pipeline-controlplane
            kind: ClusterConfiguration
            kubernetesVersion: {{.K8S_VERSION}}
            networking:
              podSubnet: "10.200.0.0/16"
            apiServerExtraArgs:
              cloud-provider: aws
              cloud-config: /etc/kubernetes/aws.conf
            apiServerExtraVolumes:
              - name: cloud-config
                hostPath: /etc/kubernetes/aws.conf
                mountPath: /etc/kubernetes/aws.conf
            controllerManagerExtraVolumes:
              - name: cloud-config
                hostPath: /etc/kubernetes/aws.conf
                mountPath: /etc/kubernetes/aws.conf
            controllerManagerExtraArgs:
              cloud-provider: aws
              cloud-config: /etc/kubernetes/aws.conf
            EOF

            printf "[GLOBAL]\nZone="$(curl -q -s http://169.254.169.254/latest/meta-data/placement/availability-zone) > /etc/kubernetes/aws.conf

            envtpl < /tmp/init.conf.tpl > /tmp/init.conf

            kubeadm init --ignore-preflight-errors=SystemVerification --config=/tmp/init.conf

            mkdir -p /root/.kube
            cp -f /etc/kubernetes/admin.conf /root/.kube/config
            chown $(id -u):$(id -g) /root/.kube/config

            mkdir -p /home/ubuntu/.kube
            cp -f /etc/kubernetes/admin.conf /home/ubuntu/.kube/config
            chown ubuntu:ubuntu /home/ubuntu/.kube/config

            export KUBECONFIG=/root/.kube/config

            # Install weave network
            kubectl apply -f "https://cloud.weave.works/k8s/net?k8s-version=$(kubectl version | base64 | tr -d '\n')"

            # Remove master label
            kubectl label node $(hostname -f) node-role.kubernetes.io/master-

            kubectl create serviceaccount --namespace kube-system tiller
            kubectl create clusterrolebinding tiller-cluster-rule --clusterrole=cluster-admin --serviceaccount=kube-system:tiller

            READY="False"

            while [ "$READY" != "True" ]; do
              READY=$(kubectl get nodes -o jsonpath='{.items[*].status.conditions[?(@.type=="Ready")].status}')
              sleep 5
            done

            helm init --service-account tiller --wait
            helm repo add banzaicloud-stable http://kubernetes-charts.banzaicloud.com/branch/master

            #######################
            # Setup storage class #
            #######################
            cat > /tmp/storageclass.yml <<EOF
              kind: StorageClass
              apiVersion: storage.k8s.io/v1
              metadata:
                name: gp2
                annotations:
                  storageclass.kubernetes.io/is-default-class: "true"
              provisioner: kubernetes.io/aws-ebs
              parameters:
                type: gp2
                fsType: ext4
            EOF

            kubectl create -f /tmp/storageclass.yml

            ###################
            # Install traefik #
            ###################
            cat > /tmp/traefik.yaml.tpl <<EOF
              dashboard:
                enabled: false
              rbac:
                enabled: true
              serviceType: NodePort
              service:
                nodePorts:
                  http: 30080
                  https: 30443
              cpuRequest: 100m
              memoryRequest: 20Mi
              cpuLimit: 400m
              memoryLimit: 500Mi
              kubernetes:
                ingressEndpoint:
                  useDefaultPublishedService: true
              ssl:
                enabled: true
                generateTLS: true
                insecureSkipVerify: true
                generateTLS: true
                defaultIPList:
                 - {{ .PUBLICIP }}
                defaultCN: {{ .ELB }}
            EOF

            envtpl < /tmp/traefik.yaml.tpl > /tmp/traefik.yaml
            helm upgrade --install cp-traefik stable/traefik --version 1.59.2 --wait -f /tmp/traefik.yaml

            ########################
            # Install mysql server #
            ########################
            cat > /tmp/mysql.yaml.tpl <<EOF
              mysqlUser: "{{ .MYSQL_USERNAME }}"
              mysqlPassword: "{{ .MYSQL_PASSWORD}}"
              initializationFiles:
                create-db-for-pipeline.sql: |-
                  CREATE DATABASE IF NOT EXISTS pipeline;
                create-db-for-cicd.sql: |-
                  CREATE DATABASE IF NOT EXISTS drone;
                grant-access.sql: |-
                  GRANT ALL PRIVILEGES ON pipeline.* TO 'pipeline-rw'@'%';
                  GRANT ALL PRIVILEGES ON drone.* TO 'pipeline-rw'@'%';
                flush.sql: |-
                  FLUSH PRIVILEGES;
              configurationFiles:
                mysql.cnf: |-
                  [mysqld]
                  skip-host-cache
                  skip-name-resolve
                  sql-mode=STRICT_TRANS_TABLES,NO_ZERO_IN_DATE,NO_ZERO_DATE,ERROR_FOR_DIVISION_BY_ZERO,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION
              persistence:
                enabled: true
            EOF

            envtpl < /tmp/mysql.yaml.tpl > /tmp/mysql.yaml
            helm upgrade --install cp-mysql stable/mysql --version 0.13.1 --wait -f /tmp/mysql.yaml

            ######################
            # Install postgresql #
            ######################
            cat > /tmp/postgresql.yaml.tpl <<EOF
              postgresUser: "{{ .PGSQL_USERNAME }}"
              postgresPassword: "{{ .PGSQL_PASSWORD }}"
              postgresDatabase: "anchore"
            EOF
            envtpl < /tmp/postgresql.yaml.tpl > /tmp/postgresql.yaml
            helm upgrade --install cp-postgresql stable/postgresql --version 0.18.0 --wait -f /tmp/postgresql.yaml

            ##############
            # Install ui #
            ##############
            cat > /tmp/pipeline-ui.yaml.tpl <<EOF
              tag: custom
              apiUrl: https://{{ .ELB }}
              cloudinfoUrl: https://beta.banzaicloud.io/cloudinfo
              ingress:
                enabled: true
                hosts:
                 - "{{ .ELB }}/ui"
                annotations:
                  kubernetes.io/ingress.class: traefik
                  kubernetes.io/ingress.ssl-redirect: "true"
              extraEnv:
                - name: CREATE_ISSUE_DISABLED
                  value: true
            EOF
            envtpl < /tmp/pipeline-ui.yaml.tpl > /tmp/pipeline-ui.yaml

            helm upgrade --install cp-ui banzaicloud-stable/pipeline-ui --version 1.0.0 --wait -f /tmp/pipeline-ui.yaml --wait

            ######################
            # Install telescopes #
            ######################
            cat > /tmp/telescopes.yaml.tpl <<EOF
              app:
                cloudInfoAddress: https://beta.banzaicloud.io/cloudinfo/api/v1
                devMode: true
              ingress:
                enabled: true
                hosts:
                 - "{{ .ELB }}/recommender"
                annotations:
                  kubernetes.io/ingress.class: traefik
                  kubernetes.io/ingress.ssl-redirect: "true"
            EOF
            envtpl < /tmp/telescopes.yaml.tpl > /tmp/telescopes.yaml

            helm upgrade --install cp-telescopes banzaicloud-stable/telescopes --version 0.1.13 --wait -f /tmp/telescopes.yaml

            ################
            # Install cicd #
            ################
            cat > /tmp/cicd.yaml.tpl <<EOF
              global:
                auth:
                  clientid: "{{ .GITHUB_CLIENT }}"
                  clientsecret: "{{ .GITHUB_SECRET }}"
              ingress:
                enabled: true
                hosts:
                - "{{ .ELB }}/build"
                annotations:
                  kubernetes.io/ingress.class: traefik
                  kubernetes.io/ingress.ssl-redirect: "true"
                  traefik.frontend.rule.type: PathPrefixStrip
              mysql:
                host: "cp-mysql"
                existingSecret: "cp-mysql"
            EOF
            envtpl < /tmp/cicd.yaml.tpl > /tmp/cicd.yaml

            helm upgrade --install cp-cicd banzaicloud-stable/cicd --version 1.0.3 --wait -f /tmp/cicd.yaml

            ##################
            #  Install vault #
            ##################
            cat > /tmp/vault.yaml.tpl <<EOF
              unsealer:
                metrics:
                  enabled: false
                  serviceMonitor:
                    enabled: false
                args:
                - --mode
                - aws-kms-s3
                - --aws-kms-key-id
                - {{ .VAULT_KMS_KEY_ID }}
                - --aws-kms-region
                - {{ .AWS_REGION }}
                - --aws-s3-region
                - {{ .AWS_REGION }}
                - --aws-s3-bucket
                - {{ .VAULT_S3_BUCKET }}
              vault:
                config:
                  storage:
                    s3:
                      bucket: {{ .VAULT_S3_BUCKET }}
                      region: {{ .AWS_REGION }}
                externalConfig:
                  policies:
                  - name: allow_accesstokens_and_orgs
                    rules: path "secret/data/accesstokens/*" {
                      capabilities = ["create", "read", "update"]
                      }
                      path "secret/metadata/accesstokens/*" {
                      capabilities = ["delete", "list"]
                      }
                      path "secret/data/orgs/*" {
                      capabilities = ["create", "read", "update"]
                      }
                      path "secret/metadata/orgs/*" {
                      capabilities = ["delete", "list"]
                      }
                      path "secret/data/banzaicloud/*" {
                      capabilities = ["create", "read"]
                      }
                      path "secret/metadata/banzaicloud/*" {
                      capabilities = ["list"]
                      }
                  auth:
                  - type: kubernetes
                    # Allows creating roles in Vault which can be used later on for the Kubernetes based
                    # authentication.
                    # See https://www.vaultproject.io/docs/auth/kubernetes.html#creating-a-role for
                    # more information.
                    roles:
                    # Allow pipeline pod in the all namespaces to use the secret kv store
                    - name: pipeline
                      bound_service_account_names: pipeline
                      bound_service_account_namespaces: "*"
                      policies: allow_accesstokens_and_orgs
                      ttl: 1h
                  secrets:
                  - path: secret
                    type: kv
                    description: General secrets.
                    options:
                      version: 2
            EOF
            envtpl < /tmp/vault.yaml.tpl > /tmp/vault.yaml

            helm upgrade --install cp-vault banzaicloud-stable/vault --version 0.5.23 --wait -f /tmp/vault.yaml

            ###################
            # Install anchore #
            ###################
            cat > /tmp/anchore.yaml.tpl <<EOF
              postgresql:
                enabled: false
                postgresUser: "{{ .PGSQL_USERNAME }}"
                postgresPassword: "{{ .PGSQL_PASSWORD }}"
                postgresDatabase: "anchore"
                externalEndpoint: "cp-postgresql.default.svc.cluster.local:5432"
            EOF

            envtpl < /tmp/anchore.yaml.tpl > /tmp/anchore.yaml
            helm upgrade --install cp-anchore banzaicloud-stable/anchore-engine --version 0.2.7 --wait -f /tmp/anchore.yaml

            ####################
            # Install pipeline #
            ####################
            cat > /tmp/pipeline.yaml.tpl <<EOF
              anchore:
                enabled: true
                secretName: cp-anchore-anchore-engine
                serviceEndpoint: https://{{ .ELB }}/imagecheck

              ark:
                logLevel: info
                syncEnabled: true

              auth:
                cookieDomain: {{ .ELB }}
                jwtaudience: {{ .FQDN }}
                jwtissueer: {{ .FQDN }}
                setCookieDomain: true

              cicd:
                url: https://{{ .ELB }}/build

              database:
                autoMigrateEnabled: true

              eks:
                templateLocation: https://raw.githubusercontent.com/banzaicloud/pipeline/{{ .PIPELINE_VERSION }}/templates/eks
              image:
                pullPolicy: Always
                tag: {{ .PIPELINE_VERSION }}
              ingress:
                annotations:
                  kubernetes.io/ingress.class: traefik
                  kubernetes.io/ingress.ssl-redirect: "true"
                enabled: true
                hosts:
                - {{ .ELB }}/

              mysql:
                enabled: false
                mysqlUser: "{{ .MYSQL_USERNAME }}"
                mysqlPassword: "{{ .MYSQL_PASSWORD}}"
                externalEndpoint: cp-mysql.default

              global:
                auth:
                  clientid: {{ .GITHUB_CLIENT }}
                  clientsecret: {{ .GITHUB_SECRET}}
                pipelineHost: {{ .FQDN }}}

              vault:
                serviceAddress: https://cp-vault.default:8200

              github:
                token: {{ .GITHUB_TOKEN }}
            EOF

            envtpl < /tmp/pipeline.yaml.tpl > /tmp/pipeline.yaml
            helm upgrade --install cp-pipeline banzaicloud-stable/pipeline --version 0.1.5 --wait -f /tmp/pipeline.yaml

            curl -X PUT -H 'Content-Type: ' --data-binary "{\"Status\":\"SUCCESS\",\"Reason\":\"Configuration Complete\",\"UniqueId\":\"$(date +%s)\"}" $SIGNAL_URL

          - {
            SignalUrl: !Ref WaitConditionHandle,
            GithubClient: !Ref GithubClient,
            GithubSecret: !Ref GithubSecret,
            GithubToken: !Ref GithubToken,
            AwsRegion: !Ref 'AWS::Region',
            VaultBucketName: !Ref VaultS3Bucket,
            VaultKMSKeyID: !Ref VaultKMSKey,
            PipelineVersion: !Ref PipelineVersion,
            ELB: !GetAtt ElasticLoadBalancer.DNSName,
          }

      SecurityGroups:
      - !Ref InstanceSecurityGroup
      KeyName: !Ref KeyName
      BlockDeviceMappings:
      - DeviceName: /dev/sda1
        Ebs:
          VolumeSize: '50'

  InstanceSecurityGroup:
    Type: 'AWS::EC2::SecurityGroup'
    Properties:
      GroupDescription: 'Enable SSH & HTTP access via port 22, 80'
      SecurityGroupIngress:
      - IpProtocol: tcp
        FromPort: '22'
        ToPort: '22'
        CidrIp: !Ref SSHLocation
      - IpProtocol: tcp
        FromPort: 30080
        ToPort: 30080
        SourceSecurityGroupName: !GetAtt ElasticLoadBalancer.SourceSecurityGroup.GroupName
      - IpProtocol: tcp
        FromPort: 30443
        ToPort: 30443
        SourceSecurityGroupName: !GetAtt ElasticLoadBalancer.SourceSecurityGroup.GroupName

  WaitConditionHandle:
    Type: AWS::CloudFormation::WaitConditionHandle

  WaitCondition:
    Type: AWS::CloudFormation::WaitCondition
    DependsOn: ControlPlaneGroup
    Properties:
      Handle:
        Ref: "WaitConditionHandle"
      Timeout: 1200

  InstanceRole:
    Type: AWS::IAM::Role
    Properties:
      RoleName: !Join [ "", [ !Ref "AWS::StackName" , "-pipeline-cp" ] ]
      Path: /
      AssumeRolePolicyDocument:
        Version: "2012-10-17"
        Statement:
        -
          Effect: "Allow"
          Principal:
            Service:
            - "ec2.amazonaws.com"
          Action:
          - "sts:AssumeRole"
      Policies:
      - PolicyName: !Join [ "", [ !Ref "AWS::StackName" , "-pipeline-cp" ] ]
        PolicyDocument:
          Version: "2012-10-17"
          Statement:
          - Action: ['s3:GetObject', 's3:PutObject']
            Effect: Allow
            Resource:
            - !Join ['', ['arn:aws:s3:::', !Ref 'VaultS3Bucket', /*]]
          - Action: ['s3:ListBucket']
            Effect: Allow
            Resource:
            - !Join ['', ['arn:aws:s3:::', !Ref 'VaultS3Bucket']]
          - Action:  ['kms:Encrypt', 'kms:Decrypt']
            Effect: Allow
            Resource:
            - !Join ['', ['arn:aws:kms:', !Ref 'AWS::Region', ':', !Ref 'AWS::AccountId', ':key/', !Ref 'VaultKMSKey']]

          - Action: [
            'autoscaling:DescribeAutoScalingGroups',
            'autoscaling:DescribeLaunchConfigurations',
            'autoscaling:DescribeTags',
            'ec2:DescribeInstances',
            'ec2:DescribeRegions',
            'ec2:DescribeRouteTables',
            'ec2:DescribeSecurityGroups',
            'ec2:DescribeSubnets',
            'ec2:DescribeVolumes',
            'ec2:CreateSecurityGroup',
            'ec2:CreateTags',
            'ec2:CreateVolume',
            'ec2:ModifyInstanceAttribute',
            'ec2:ModifyVolume',
            'ec2:AttachVolume',
            'ec2:AuthorizeSecurityGroupIngress',
            'ec2:CreateRoute',
            'ec2:DeleteRoute',
            'ec2:DeleteSecurityGroup',
            'ec2:DeleteVolume',
            'ec2:DetachVolume',
            'ec2:RevokeSecurityGroupIngress',
            'ec2:DescribeVpcs',
            'elasticloadbalancing:AddTags',
            'elasticloadbalancing:AttachLoadBalancerToSubnets',
            'elasticloadbalancing:ApplySecurityGroupsToLoadBalancer',
            'elasticloadbalancing:CreateLoadBalancer',
            'elasticloadbalancing:CreateLoadBalancerPolicy',
            'elasticloadbalancing:CreateLoadBalancerListeners',
            'elasticloadbalancing:ConfigureHealthCheck',
            'elasticloadbalancing:DeleteLoadBalancer',
            'elasticloadbalancing:DeleteLoadBalancerListeners',
            'elasticloadbalancing:DescribeLoadBalancers',
            'elasticloadbalancing:DescribeLoadBalancerAttributes',
            'elasticloadbalancing:DetachLoadBalancerFromSubnets',
            'elasticloadbalancing:DeregisterInstancesFromLoadBalancer',
            'elasticloadbalancing:ModifyLoadBalancerAttributes',
            'elasticloadbalancing:RegisterInstancesWithLoadBalancer',
            'elasticloadbalancing:SetLoadBalancerPoliciesForBackendServer',
            'elasticloadbalancing:AddTags',
            'elasticloadbalancing:CreateListener',
            'elasticloadbalancing:CreateTargetGroup',
            'elasticloadbalancing:DeleteListener',
            'elasticloadbalancing:DeleteTargetGroup',
            'elasticloadbalancing:DescribeListeners',
            'elasticloadbalancing:DescribeLoadBalancerPolicies',
            'elasticloadbalancing:DescribeTargetGroups',
            'elasticloadbalancing:DescribeTargetHealth',
            'elasticloadbalancing:ModifyListener',
            'elasticloadbalancing:ModifyTargetGroup',
            'elasticloadbalancing:RegisterTargets',
            'elasticloadbalancing:SetLoadBalancerPoliciesOfListener',
            'iam:CreateServiceLinkedRole',
            'kms:DescribeKey' ]
            Effect: Allow
            Resource: '*'

  InstanceProfile:
    Type: 'AWS::IAM::InstanceProfile'
    Properties:
      Path: /
      Roles:
      - !Ref InstanceRole
      InstanceProfileName: !Join [ "", [ !Ref "AWS::StackName" , "-pipeline-cp" ] ]

Outputs:
  UI:
    Description: 'Control Plane UI:'
    Value: !Join
    - ''
    - - 'https://'
      - !GetAtt ElasticLoadBalancer.SourceSecurityGroup.GroupName
      - /

Metadata:
  'AWS::CloudFormation::Interface':
    ParameterGroups:
    - Label:
        default: Control Plane Instance Config
      Parameters:
      - InstanceName
      - InstanceType
      - KeyName

    - Label:
        default: Github oauth credentials
      Parameters:
      - GithubClient
      - GithubSecret

    - Label:
        default: Github credentials
      Parameters:
      - GithubToken

    ParameterLabels:
      GithubClient:
        default: Github Client
      GithubSecret:
        default: Github Secret

